# Варианты заданий по курсу «Сетевое программирование»

## Примеры заданий по сокетам и протоколам:
1. Простейший TCP-WHOIS-сервер, который будет отдавать информацию о доменах
2. Простейший HTTPS-proxy, который бы проксировал в Anthropic / OpenAI
3. UDP-сервер времени (SNTP-like)
4. Простой DNS-резолвер (в виде TCP-сервера)
5. Простейший WebSocket-сервер
6. Любая ваша собственная задача связанная с TCP/UDP клиентом или сервером

## Примеры заданий по асинхронному программированию (asyncio):
1. Crowler по сайтам (забрать метаданные с каждого сайта)
2. Нагрузочный тестер для сайтов
3. Асинхронная скачивалка изображений

---

## Задания по сокетам и протоколам

### Простейший TCP-WHOIS-сервер, который будет отдавать информацию о доменах

На TCP-сервер получает от клиента строку с именем домена, затем 2 варианта:
1. Идём в каталог `DOMAIN_DIR` и там находим текстовый файл с именем домена, например `example.com`, если находим — отдаём содержимое текстового файла, закрываем соединение, если не нашли — пишем `Domain not found`.
   В этом случае надо будет создать тестовый каталог с информацией о нескольких доменах, на которых будем тестировать.
2. Используем любую библиотеку для получения WHOIS по реальному домену и отдаём результат, закрываем соединение. В этом случае мы напишем WHOIS proxy.
### Простейший HTTPS-proxy, который бы проксировал в Anthropic / OpenAI

Сделать HTTPS-proxy, например на базе Flask для проксирования запросов в Anthropic / OpenAI. Нужно для обхода блокировок Российских IP, как альтернатива VPN.
Желательно если все запросы / ответы будут логироваться в файл.
Также нужна поддержка белого списка IP, которым мы разрешает отсылать запросы: `ALLOWED_IPS`. Оно должно быть протестировано и реально работать для OpenAI или Anthropic. Поддержка режима `stream` (постепенной отдачи контента) не нужна, т.к. это слишком усложняет задачу.
### UDP-сервер времени (SNTP-like)

Реализовать UDP-сервер, который возвращает текущее время в UTC в простом формате (например, ISO 8601).
**Клиент:** отправляет пустой пакет или специальную команду, сервер возвращает строку с временем.
**Дополнительно:** можно сделать клиента, который опрашивает несколько таких серверов и сравнивает разницу.
### Простой DNS-резолвер

Получает запрос по UDP по протоколу DNS (от любого DNS-клиента, например nslookup), резолвит имя домена любым способом (можно просто вызвать готовые функции) и отдаёт результат в виде DNS-пакета.
### Простейший WebSocket-сервер
Реализовать WebSocket-сервер, который рассылает клиентам данные (например, текущую дату каждую секунду или случайные числа).
**Клиент:** простой HTML + JS фронт.
**Бонус:** сделать чат или между другими клиентами (всё что написал любой пользователь в чате — пересылается всем).
## Задания по асинхронному программированию
### Crowler по сайтам (забрать метаданные с каждого сайта)
Дан список доменов в формате .CSV (10000 доменов), нужно асинхронно (с помощью любой асинхронной библиотеки поддерживающей HTTP / HTTPS) обратиться к данным сайтам и запросить главную страницу. По каждому домену / сайту обратиться вначале по HTTP затем по HTTPS и получить следующую информацию, следующие поля:
   - http_status — результат обращения на главную страницу по HTTP: код возврата (200, 303 и т.п.), если не удалось установить соединение / получить ответ — None
   - http_server — содержимое заголовка Server в ответе сервера или None если запрос неуспешен
   - http_content_length — длина response body в байтах (может быть 0) или None если запрос неуспешен
   - http_content_language — содержимое заголовка ответа "Content-Language", в виде списка, если этот заголовок есть или пустой список
   - http_cookies — список кук которые нам отдал сервер, если отдал или пустой список
   - https_status — Удалось ли успешно установить соединение, `Ok` если удалось, а если нет — написать ошибку TLS (в любом читаемом формате)
   - https_status, https_server, https_content_length, http_content_language, https_status, https_cookies — всё аналогично соответствующим полям http_*
В запросе указать заголовок Accept-Language: ru-RU!
Всё должно работать полностью асинхронно (включая резолвинг DNS), ограничение — 1000 одновременных соединений.
Итоговый результат положить в файл domain_status в виде JSON — список словарей с указанными выше полями. При этом http_cookies, http_content_language — списки (могут быть пустые списки)
Список сайтов тут: https://github.com/xtrueman/network_programming/blob/main/data/top-10k.csv.gz
Но можете взять любой другой список
### Нагрузочный тестер для сайтов
Написать на python с применением любой библиотеки для асинхронного HTTP/HTTPS скрипт для нагрузочного тестирования сайтов (по HTTP или HTTPS).
На входе (в командной строке или в конфиге):
1. URL сайта, который тестируем, например `https://www.bitrix24.ru/prices/`
2. Количество запросов в секунду (RPS), например `100`
3. Количество секунд, которые тестируем (test_time), например, `10`
4. Таймаут сколько подождать завершения ответов на запросы (wait_timeout) после того как истечёт test_time, например `5`

Нужно равномерно инициировать в течение test_time RPS запросов в секунду, потом подождать test_time секунд. Проанализировать / агрегировать результаты.

Представить итоговый результат например в таком виде:
```
Target URL: https://www.bitrix24.ru/prices/
Test duration: 10s, RPS: 100 (total 1000 requests)
Timeout for responses: 5s

=== Request Summary ===
Total requests sent:    1000
Completed successfully:  845
Failed requests:      155
- Timeout errors:     112
- Connection errors:  31
- HTTP errors (5xx):  12

=== Response Time (ms) ===
Min:     48
Max:   4012
Mean:   523.7
Median: 217
p75:    312
p90:    743
p95:   1031
p99:   2561

=== Status Code Distribution ===
200 OK:         832
301 Redirect:    13
500 Server Err:  10
Timeouts:       112
```
Задание и формат вывода можно видоизменить по вашему выбору.

### Асинхронная скачивалка изображений

Получить список URL-адресов изображений из CSV и асинхронно скачать все изображения в каталог, ограничив одновременные загрузки (например, 20 параллельно).
Особенности: логировать прогресс, обработать ошибки.
### Асинхронный мониторинг сайтов

Простейший uptime-monitor.
Асинхронно проверять доступность списка сайтов (список задан например в виде CSV файла или в базе или где-то ещё) (по HEAD или GET-запросу), каждые N секунд, и логировать изменение статуса. Проверяем HTTP status.
Если статус сайта изменился с "рабочего" на "нерабочий", например статус с 200 на 502, то отсылаем alert (в виде сообщения в телеграме или SMS или email или в ином виде) на контакт, указанный в CSV-файле.
Пример CSV-файла:
```CSV
DOMAIN_NAME;tg_username,email
example.com,@xtrueman22,xtrueman22@gmail.com
mizulina.ru,@mizulina,mizulina@shaman.com
```
